{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a4ccfe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "36278ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"./data/orochi_data/clapping.txt\",\n",
    "         \"./data/orochi_data/fingersnap.txt\",]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for idx, file in enumerate(files):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        df = pd.DataFrame([x.split() for x in lines[0:120]])\n",
    "        df.drop(columns=[0, 1, 2, 3, 4, 5, 8, 9], inplace=True)\n",
    "        # add another column with the file name\n",
    "        df[\"gesture\"] = idx\n",
    "        df.columns = [\"f1\", \"f2\", \"gesture\"]\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "731d9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for d in dfs:\n",
    "    df = pd.concat([df, d], ignore_index=True)\n",
    "    \n",
    "X = df[[\"f1\", \"f2\"]]\n",
    "y = df[\"gesture\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "30dfe311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X from hex string to int\n",
    "X = X.map(lambda x: int(x, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4c1dccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "87389083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pyth\\radarobj_detection\\radarml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "shape = (2,3,2)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(shape[1], activation='relu', input_shape=(shape[0],), name=\"hidden\"),\n",
    "    Dense(shape[2], activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a75337c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5141 - loss: 5.3503 - val_accuracy: 0.3846 - val_loss: 6.2097\n",
      "Epoch 2/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5046 - loss: 4.9695 - val_accuracy: 0.3846 - val_loss: 5.7148\n",
      "Epoch 3/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5211 - loss: 4.2868 - val_accuracy: 0.3846 - val_loss: 5.2240\n",
      "Epoch 4/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5406 - loss: 3.8270 - val_accuracy: 0.3846 - val_loss: 4.7279\n",
      "Epoch 5/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5150 - loss: 3.6968 - val_accuracy: 0.3846 - val_loss: 4.2245\n",
      "Epoch 6/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5076 - loss: 3.2701 - val_accuracy: 0.3846 - val_loss: 3.7239\n",
      "Epoch 7/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5706 - loss: 2.4943 - val_accuracy: 0.3846 - val_loss: 3.2361\n",
      "Epoch 8/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5376 - loss: 2.3297 - val_accuracy: 0.3846 - val_loss: 2.7443\n",
      "Epoch 9/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5415 - loss: 1.9712 - val_accuracy: 0.3846 - val_loss: 2.2534\n",
      "Epoch 10/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5358 - loss: 1.6003 - val_accuracy: 0.3846 - val_loss: 1.7756\n",
      "Epoch 11/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5302 - loss: 1.2656 - val_accuracy: 0.3846 - val_loss: 1.3366\n",
      "Epoch 12/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5081 - loss: 0.9681 - val_accuracy: 0.3846 - val_loss: 0.9751\n",
      "Epoch 13/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6149 - loss: 0.6420 - val_accuracy: 0.4359 - val_loss: 0.7313\n",
      "Epoch 14/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7501 - loss: 0.5223 - val_accuracy: 0.6154 - val_loss: 0.5743\n",
      "Epoch 15/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8344 - loss: 0.4441 - val_accuracy: 0.7179 - val_loss: 0.4892\n",
      "Epoch 16/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8566 - loss: 0.4105 - val_accuracy: 0.8462 - val_loss: 0.4448\n",
      "Epoch 17/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9074 - loss: 0.4071 - val_accuracy: 0.8462 - val_loss: 0.4218\n",
      "Epoch 18/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9044 - loss: 0.3962 - val_accuracy: 0.8462 - val_loss: 0.4079\n",
      "Epoch 19/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8896 - loss: 0.4081 - val_accuracy: 0.8462 - val_loss: 0.4007\n",
      "Epoch 20/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8840 - loss: 0.4020 - val_accuracy: 0.8462 - val_loss: 0.3961\n",
      "Epoch 21/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9078 - loss: 0.3805 - val_accuracy: 0.8462 - val_loss: 0.3931\n",
      "Epoch 22/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9187 - loss: 0.3578 - val_accuracy: 0.8462 - val_loss: 0.3911\n",
      "Epoch 23/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8992 - loss: 0.3880 - val_accuracy: 0.8462 - val_loss: 0.3908\n",
      "Epoch 24/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9100 - loss: 0.3732 - val_accuracy: 0.8462 - val_loss: 0.3901\n",
      "Epoch 25/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8992 - loss: 0.3701 - val_accuracy: 0.8462 - val_loss: 0.3898\n",
      "Epoch 26/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8770 - loss: 0.4075 - val_accuracy: 0.8462 - val_loss: 0.3903\n",
      "Epoch 27/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9070 - loss: 0.3647 - val_accuracy: 0.8718 - val_loss: 0.3887\n",
      "Epoch 28/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8966 - loss: 0.3913 - val_accuracy: 0.8718 - val_loss: 0.3888\n",
      "Epoch 29/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9183 - loss: 0.3776 - val_accuracy: 0.8718 - val_loss: 0.3879\n",
      "Epoch 30/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8975 - loss: 0.3649 - val_accuracy: 0.8718 - val_loss: 0.3862\n",
      "Epoch 31/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9152 - loss: 0.3522 - val_accuracy: 0.8718 - val_loss: 0.3841\n",
      "Epoch 32/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9126 - loss: 0.3535 - val_accuracy: 0.8718 - val_loss: 0.3827\n",
      "Epoch 33/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9083 - loss: 0.3480 - val_accuracy: 0.8718 - val_loss: 0.3803\n",
      "Epoch 34/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9044 - loss: 0.3677 - val_accuracy: 0.8718 - val_loss: 0.3770\n",
      "Epoch 35/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8948 - loss: 0.3790 - val_accuracy: 0.8718 - val_loss: 0.3739\n",
      "Epoch 36/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8918 - loss: 0.3545 - val_accuracy: 0.9231 - val_loss: 0.3705\n",
      "Epoch 37/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8922 - loss: 0.3606 - val_accuracy: 0.9231 - val_loss: 0.3672\n",
      "Epoch 38/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8749 - loss: 0.3715 - val_accuracy: 0.9231 - val_loss: 0.3643\n",
      "Epoch 39/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8970 - loss: 0.3360 - val_accuracy: 0.9231 - val_loss: 0.3613\n",
      "Epoch 40/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8775 - loss: 0.3712 - val_accuracy: 0.9231 - val_loss: 0.3587\n",
      "Epoch 41/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8788 - loss: 0.3632 - val_accuracy: 0.9231 - val_loss: 0.3560\n",
      "Epoch 42/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9100 - loss: 0.3371 - val_accuracy: 0.9231 - val_loss: 0.3533\n",
      "Epoch 43/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8853 - loss: 0.3512 - val_accuracy: 0.9231 - val_loss: 0.3509\n",
      "Epoch 44/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8892 - loss: 0.3758 - val_accuracy: 0.9231 - val_loss: 0.3491\n",
      "Epoch 45/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9087 - loss: 0.3400 - val_accuracy: 0.9231 - val_loss: 0.3468\n",
      "Epoch 46/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9196 - loss: 0.3292 - val_accuracy: 0.9231 - val_loss: 0.3453\n",
      "Epoch 47/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9031 - loss: 0.3571 - val_accuracy: 0.9231 - val_loss: 0.3439\n",
      "Epoch 48/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8966 - loss: 0.3349 - val_accuracy: 0.9231 - val_loss: 0.3422\n",
      "Epoch 49/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8966 - loss: 0.3535 - val_accuracy: 0.9231 - val_loss: 0.3406\n",
      "Epoch 50/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9131 - loss: 0.3254 - val_accuracy: 0.9231 - val_loss: 0.3392\n",
      "Epoch 51/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9048 - loss: 0.3512 - val_accuracy: 0.9231 - val_loss: 0.3384\n",
      "Epoch 52/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9157 - loss: 0.3137 - val_accuracy: 0.9231 - val_loss: 0.3363\n",
      "Epoch 53/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8827 - loss: 0.3653 - val_accuracy: 0.9231 - val_loss: 0.3350\n",
      "Epoch 54/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8831 - loss: 0.3480 - val_accuracy: 0.9231 - val_loss: 0.3336\n",
      "Epoch 55/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8970 - loss: 0.3315 - val_accuracy: 0.9231 - val_loss: 0.3318\n",
      "Epoch 56/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9022 - loss: 0.3418 - val_accuracy: 0.9231 - val_loss: 0.3312\n",
      "Epoch 57/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9074 - loss: 0.3221 - val_accuracy: 0.9231 - val_loss: 0.3297\n",
      "Epoch 58/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8853 - loss: 0.3346 - val_accuracy: 0.9231 - val_loss: 0.3283\n",
      "Epoch 59/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8918 - loss: 0.3485 - val_accuracy: 0.9231 - val_loss: 0.3273\n",
      "Epoch 60/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8957 - loss: 0.3527 - val_accuracy: 0.9231 - val_loss: 0.3263\n",
      "Epoch 61/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9196 - loss: 0.3138 - val_accuracy: 0.9231 - val_loss: 0.3249\n",
      "Epoch 62/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9165 - loss: 0.3281 - val_accuracy: 0.9231 - val_loss: 0.3241\n",
      "Epoch 63/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9222 - loss: 0.3024 - val_accuracy: 0.9231 - val_loss: 0.3220\n",
      "Epoch 64/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8970 - loss: 0.3254 - val_accuracy: 0.9231 - val_loss: 0.3213\n",
      "Epoch 65/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9096 - loss: 0.3184 - val_accuracy: 0.9231 - val_loss: 0.3208\n",
      "Epoch 66/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9170 - loss: 0.3123 - val_accuracy: 0.9231 - val_loss: 0.3199\n",
      "Epoch 67/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9148 - loss: 0.3112 - val_accuracy: 0.9231 - val_loss: 0.3189\n",
      "Epoch 68/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8992 - loss: 0.3500 - val_accuracy: 0.9231 - val_loss: 0.3184\n",
      "Epoch 69/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8853 - loss: 0.3382 - val_accuracy: 0.9231 - val_loss: 0.3180\n",
      "Epoch 70/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9026 - loss: 0.3414 - val_accuracy: 0.9231 - val_loss: 0.3168\n",
      "Epoch 71/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8861 - loss: 0.3337 - val_accuracy: 0.9231 - val_loss: 0.3154\n",
      "Epoch 72/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8974 - loss: 0.3192 - val_accuracy: 0.9231 - val_loss: 0.3144\n",
      "Epoch 73/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9191 - loss: 0.3332 - val_accuracy: 0.9231 - val_loss: 0.3148\n",
      "Epoch 74/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9178 - loss: 0.3177 - val_accuracy: 0.9231 - val_loss: 0.3146\n",
      "Epoch 75/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9031 - loss: 0.3267 - val_accuracy: 0.9231 - val_loss: 0.3133\n",
      "Epoch 76/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8857 - loss: 0.3397 - val_accuracy: 0.9231 - val_loss: 0.3124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2d273559690>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',   # or use 'accuracy' if you want training accuracy\n",
    "    patience=40,               # number of epochs with no improvement after which training will be stopped\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=400,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b12998fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9271 - loss: 0.3330\n",
      "Test Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6350f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    clapping       1.00      0.88      0.93        24\n",
      "  fingersnap       0.89      1.00      0.94        24\n",
      "\n",
      "    accuracy                           0.94        48\n",
      "   macro avg       0.94      0.94      0.94        48\n",
      "weighted avg       0.94      0.94      0.94        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "targets = ['clapping', 'fingersnap']\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # convert from probabilities to class indices\n",
    "\n",
    "# Print report\n",
    "print(classification_report(y_test, y_pred_classes, target_names=targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "58d6b23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=targets,\n",
    "            yticklabels=targets)\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b4552c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def parse_weights(input_str):\n",
    "    # Regex to match variable entries\n",
    "    pattern = r\"<Variable path=(.*?), shape=(.*?), dtype=.*?, value=([\\s\\S]*?)>\"\n",
    "\n",
    "    matches = re.findall(pattern, input_str)\n",
    "    weights_dict = {}\n",
    "    labels = [\"input_hidden_weights\", \"hidden_biases\", \"hidden_output_weights\", \"output_biases\"]\n",
    "    idx = 0\n",
    "    for var_name, var_shape, value_str in matches:\n",
    "        # get the shape\n",
    "        var_shape = tuple(int(dim) for dim in var_shape.strip('()').split(',') if dim)\n",
    "        # Clean up variable name\n",
    "        var_name = var_name.strip()\n",
    "        cleaned_value = re.sub(r'\\s+', ' ', value_str.strip())\n",
    "        cleaned_value = cleaned_value.replace('[', '')\n",
    "        cleaned_value = cleaned_value.replace(']', '')\n",
    "        cleaned_value = cleaned_value.strip().split(' ')\n",
    "        cleaned_value = [float(x) for x in cleaned_value if x]  # Convert to float and remove empty strings\n",
    "        value = np.array(cleaned_value).reshape(var_shape)\n",
    "        weights_dict[labels[idx]] = value\n",
    "        idx += 1\n",
    "\n",
    "    return weights_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "de7baec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def evaluate_custom_mlp(X, y, weights_dict, is_categorical=False, shape=(5, 8, 2)):\n",
    "    \"\"\"\n",
    "    Evaluate accuracy of a manually-weighted MLP model.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.ndarray): Input data, shape (num_samples, 4)\n",
    "        y (np.ndarray): Labels, shape (num_samples,) or one-hot (num_samples, 3)\n",
    "        weights_dict (dict): Dictionary with keys:\n",
    "            'input_hidden_weights', 'hidden_biases',\n",
    "            'hidden_output_weights', 'output_biases'\n",
    "        is_categorical (bool): Set True if y is one-hot encoded\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy score\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Build model with matching architecture\n",
    "    model = Sequential([\n",
    "        Dense(shape[1], input_shape=(shape[0],), activation='relu', name='hidden'),\n",
    "        Dense(shape[2], activation='softmax', name='output')\n",
    "    ])\n",
    "\n",
    "    # 2. Set custom weights\n",
    "    model.get_layer('hidden').set_weights([\n",
    "        np.array(weights_dict['input_hidden_weights']),\n",
    "        np.array(weights_dict['hidden_biases'])\n",
    "    ])\n",
    "\n",
    "    model.get_layer('output').set_weights([\n",
    "        np.array(weights_dict['hidden_output_weights']),\n",
    "        np.array(weights_dict['output_biases'])\n",
    "    ])\n",
    "\n",
    "    # 3. Get predictions\n",
    "    predictions = model.predict(X)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # 4. Process ground truth\n",
    "    if is_categorical:\n",
    "        true_classes = np.argmax(y, axis=1)\n",
    "    else:\n",
    "        true_classes = y\n",
    "\n",
    "    # 5. Compute accuracy\n",
    "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6af63427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def round_weights(weights_dict, decimals=2, scale=0):\n",
    "    \"\"\"\n",
    "    Rounds all numpy array values in the input dictionary to the given number of decimals,\n",
    "    with an optional scaling factor applied before rounding.\n",
    "\n",
    "    Parameters:\n",
    "        weights_dict (dict): Dictionary with keys mapping to numpy arrays.\n",
    "        decimals (int): Number of decimal places to round to.\n",
    "        scale (int): Power of 10 to scale the values before rounding. For example,\n",
    "                     scale=2 multiplies values by 100 before rounding.\n",
    "\n",
    "    Returns:\n",
    "        dict: New dictionary with rounded values.\n",
    "    \"\"\"\n",
    "    rounded_dict = {}\n",
    "    factor = 10 ** scale\n",
    "\n",
    "    for key, value in weights_dict.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            scaled = value * factor\n",
    "            rounded = np.round(scaled, decimals)\n",
    "            rounded_dict[key] = rounded\n",
    "        else:\n",
    "            rounded_dict[key] = value  # Leave untouched if not an ndarray\n",
    "\n",
    "    return rounded_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a6dc6889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_hidden_weights': array([[ 0.2594299 , -0.3768168 ,  0.8956291 ],\n",
       "        [-0.0190575 , -0.21202719, -0.18962584]]),\n",
       " 'hidden_biases': array([-0.06014738,  0.        ,  0.09794158]),\n",
       " 'hidden_output_weights': array([[ 0.6538672 , -0.07457413],\n",
       "        [ 0.07928085,  0.85269606],\n",
       "        [-0.46889642, -0.01549624]]),\n",
       " 'output_biases': array([-0.06184732,  0.06184732])}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_weights(str(model.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7ab02a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_hidden_weights': array([[ 26., -38.,  90.],\n",
       "        [ -2., -21., -19.]]),\n",
       " 'hidden_biases': array([-6.,  0., 10.]),\n",
       " 'hidden_output_weights': array([[ 65.,  -7.],\n",
       "        [  8.,  85.],\n",
       "        [-47.,  -2.]]),\n",
       " 'output_biases': array([-6.,  6.])}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = round_weights(parse_weights(str(model.weights)), decimals=0 , scale=2)\n",
    "new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "99c71b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Accuracy: 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pyth\\radarobj_detection\\radarml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_custom_mlp(X, y, new_weights, is_categorical=False, shape=shape)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radarml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
